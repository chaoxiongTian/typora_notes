### 文本向量化

[转自](http://www.jianshu.com/p/1771213e3008?utm_source=desktop&utm_medium=timeline) [阿里云云栖社区](http://www.jianshu.com/u/12532d36e4da)

>  在自然语言处理诞生之初（NLP），需要将文本转换成机器可以理解的东西。换句话说，就是将文本转换为有意义的数字向量（或数组）。但是在深度学习的时代，我们只需用一个词袋就可以达到上述操作的效果。

#### 词袋

这种方法虽然功能强大但是其背后的理念很简单。首先，我们需要定义一个固定长度向量，其中每个条目和我们预定义的词典中的单词相对应。向量的大小等于字典的大小。然后，我们只需计算出字典里的每一个单词在文本中出现的次数，再将这个数字放在相应的向量项中，这样所得到的向量就表示一个文本。

例如，如果我们的字典包含单词{MonkeyLearn，is，the，not，great}，我们想要向量化文本“MonkeyLearn is great”，我们将会有以下向量：（1，1，0，0， 1）。

为增强它的表现能力，你可以使用一些更先进的技术，如去除省略词，lemmatizanaword，使用n-gram或使用TF_IDF，来代替计数。

但是这种方法即使使用n-gram，它也不会真正捕捉到文本的含义或单词出现的语境。

#### 深度学习正在改变文本向量化

目前，深度学习已经接管了机器学习，它做了很多改变文本向量化方式的尝试，并找到更好的方式来表示文本。

为解决上述问题首先需要找到一种向量化单词（vectorize words）的方式，word2vec的实现为解决这个问题起到了很大的作用，也因此在2013年之后变得非常受欢迎。通过使用大量数据，可以让神经网络学习一些具有理想属性词的向量表示。例如，使用wor2vec，您可以执行“king” - “man”+“woman”，结果会得到一个与向量“Queen”非常相似的向量。这看起来有点魔幻，但是通过这个微博，你将会发现这是有可能发生的。这些向量的每一个维度可以编码出该单词的不同属性，这对于执行和NLP相关的许多任务是有用的。例如，据此你可以描述出该单词是动词还是名词，或者该单词是否为复数形式。

下一步是获取整个句子的向量化，这对于文本分类非常有用。尽管如此这个问题还是没有完全解决，但是在过去几年里，像skip-thought vectors类似技术的实现，在该方面还是取得了很大的进展。

####转移学习

在机器学习领域，转移学习是指机器将在一个任务中得到的学习观念运用到另一个任务中的能力。对于你面临的每个新问题，你需要从头开始执行所有向量化，这是通过词袋方法进行文本向量化的过程中存在一个问题。

这个问题在人与人的交往中并不存在，我们知道某些词的含义可能随着不同的背景而改变，但是我们不需要每次遇到这个词都重复学习一遍。

而深度学习则具有能够在多个不同问题中使用的文本向量化的能力，不必一次又一次地重复学习。

#### Skip-Thoughts向量

未整理完.....

